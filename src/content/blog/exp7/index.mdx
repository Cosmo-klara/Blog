---
title: '更多音频压缩相关工作和一个实验'
publishDate: '2026-01-15'
updatedDate: '2026-01-22'
description: '记录每周的工作内容'
tags:
    - Record
    - Weekly_work
language: '中文'
---

## Record

在  可以获取本周的代码变动

## TODO

- [ ] layer1 attn (AVT)
- [x] lossy  FFT / Audio compress
- [x] h264 关键帧 vs deltas
- [ ] 汇总表格

### h264 的压缩方法

1、分组：把几帧图像分为一组（GOP，也就是一个序列，第一帧-IDR 帧，一定是 I 帧），为防止运动变化，帧数不宜取多
2、定义帧：将每组内各帧图像定义为三种类型，即 I 帧、B 帧和 P 帧
3、预测帧：以 I 帧作为基础帧，以 I 帧预测 P 帧，再由 I 帧和 P 帧预测 B 帧
4、数据传输：最后将 I 帧数据与预测的差值信息进行存储和传输

I帧、B帧、P帧：

I帧：
- 全帧编码：I 帧是关键帧，包含完整的图像信息，不依赖于其他帧。
- 帧内压缩：I 帧通过帧内压缩技术，类似图像 jpeg

P帧：
- 单向预测：P 帧只依赖于前一个参考帧(I 或 P，因为 P 也是参考帧，和 I 帧一样会造成解码错误的扩散)进行预测。
- 压缩效率中等：差别帧，只包含和前一帧的画面的差别，解码时需要之前缓存的画面叠加上本帧定义的差别，生成最终画面

B帧：
- 双向预测：B 帧依赖于前一帧和后一帧进行预测（不是参考帧），I-B-B-B-P-B-B-B-P-B-B-B-I-
- 压缩效率高：前后参考帧差异以外的变化部分，或者说前后两帧中没有变化的部分作为参考帧的一个 P 帧

感觉就是先在图像上压缩一下（帧内），然后在时间维度上压缩一次（帧间）


### 音频 token 压缩：

只记录相关的工作，其他的后续收录到表中：

+ SpeechPrune

|模型|压缩比|Tech & Science | Culture & Politics | Daily Life | Film & TV | Performance | Games | Sports | Music | Avg.|
|------------------------------|------|------|------|------|------|------|------|------|------|------|------|
|Qwen2.5-omni baseline(V only)|  50% | 48.1 | 48.5 | 42.3 | 43.3 | 39.7 | 43.4 | 42.1 | 43.0 | 44.0 |



### baseline 设计

fps 配置上使用 Qwen2.5-omni 原生配置 2，分辨率依然使用原生的动态分辨率

视觉上参考 DyCoke 的第一阶段进行剪枝，第一阶段剪枝在预填充阶段，将视频帧序列分组，在组内进行时间维度剪枝 token
音频上使用音频编码器的最后一层，并计算注意力矩阵，标记重要性量化为每个音频标记从所有其他音频标记接收的平均注意力，以此进行剪枝，低于某个阈值（这个要等实验去看数据集中的分布可能）的音频标记将被移除。

### 实验设计

在 baseline 基础上直接通过计算 V / A 双向注意力后，按照时间块分组进行 V/A token 压缩

在 baseline 基础上，在 V/A 过 MLP 投影且分组交错后加双向注意力得到 N_a + N_v 个 融合token，参照 EchoingPixels ？



### TODO

在 WorldSense 上评估 baseline：

由于 75 上面卡坏了，暂时跑不了实验了, 查了下说是过热或者缺电自我保护断开服务了，得等管服务器的人重启服务器了

```shell
Unable to determine the device handle for GPU0000:B2:00.0: Unknown Error
```












