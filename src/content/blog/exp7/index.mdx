---
title: '更多音频压缩相关工作和一个实验'
publishDate: '2026-01-15'
updatedDate: '2026-01-22'
description: '记录每周的工作内容'
tags:
    - Record
    - Weekly_work
language: '中文'
---

## Record

在  可以获取本周的代码变动

## TODO

- [ ] layer1 attn (AVT)
- [x] lossy  FFT / Audio compress
- [x] h264 关键帧 vs deltas
- [ ] 汇总表格

### h264 的压缩方法

1、分组：把几帧图像分为一组（GOP，也就是一个序列，第一帧-IDR 帧，一定是 I 帧），为防止运动变化，帧数不宜取多
2、定义帧：将每组内各帧图像定义为三种类型，即 I 帧、B 帧和 P 帧
3、预测帧：以 I 帧作为基础帧，以 I 帧预测 P 帧，再由 I 帧和 P 帧预测 B 帧
4、数据传输：最后将 I 帧数据与预测的差值信息进行存储和传输

I帧、B帧、P帧：

I帧：
- 全帧编码：I 帧是关键帧，包含完整的图像信息，不依赖于其他帧。
- 帧内压缩：I 帧通过帧内压缩技术，类似图像 jpeg

P帧：
- 单向预测：P 帧只依赖于前一个参考帧(I 或 P，因为 P 也是参考帧，和 I 帧一样会造成解码错误的扩散)进行预测。
- 压缩效率中等：差别帧，只包含和前一帧的画面的差别，解码时需要之前缓存的画面叠加上本帧定义的差别，生成最终画面

B帧：
- 双向预测：B 帧依赖于前一帧和后一帧进行预测（不是参考帧），I-B-B-B-P-B-B-B-P-B-B-B-I-
- 压缩效率高：前后参考帧差异以外的变化部分，或者说前后两帧中没有变化的部分作为参考帧的一个 P 帧

感觉就是先在图像上压缩一下（帧内），然后在时间维度上压缩一次（帧间）


### 音频 token 压缩：

只记录相关的工作，其他的后续收录到表中：

+ SpeechPrune




> 在 EchoingPixels 中报告的 Qwen2.5-omni-3B 在  WorldSense benchmark 上的得分是 45.4，不过里面说了是 Audio-Visual Tasks

### baseline 设计

fps 配置上使用 Qwen2.5-omni 原生配置 2，分辨率依然使用原生的动态分辨率

视觉上参考 DyCoke 的第一阶段进行剪枝，第一阶段剪枝在预填充阶段，将视频帧序列分组，在组内进行时间维度剪枝 token
音频上使用音频编码器的最后一层，并计算注意力矩阵，标记重要性量化为每个音频标记从所有其他音频标记接收的平均注意力，以此进行剪枝，低于某个阈值（这个要等实验去看数据集中的分布可能）的音频标记将被移除。

### 一个实验结果


|模型|压缩比|Tech & Science | Culture & Politics | Daily Life | Film & TV | Performance | Games | Sports | Music | Avg.|
|------------------------------|------|------|------|------|------|------|------|------|------|------|
| Qwen2.5-omni-3B（数据来源自 Omnizip 论文） | 100%   | 51.5 | 50.8 | 45.0 | 45.4 | 43.8 | 42.5 | 44.2 | 46.1 | 46.4 |
| Qwen2.5-omni-3B baseline(V only)* |  50%（V）     | 48.0 | 47.3 | 41.8 | 42.1 | 39.6 | 42.8 | 41.0 | 43.3 | 43.6 |
| Qwen2.5-omni-3B DyCoke (V&A)      |  50%          | 48.1 | 48.5 | 42.3 | 43.3 | 39.7 | 43.4 | 42.1 | 43.0 | 44.0 |


测的是仅视觉的 token 压缩，采用的 DyCoke 第一阶段类似的方法，分块压缩视觉 token，不过关键帧选择不是默认块的第一帧，选的是块内与其他块平均相似度最低的块（这个我看了 h264 之后感觉或者用相似度最高的作为关键帧也可以，这样其他的压缩相当于就算 P 和 B 帧），其他帧根据关键帧进行冗余度计算，topk剪枝，还有个以此音频剪枝的还没测，卡坏了

可以看到和 Omnizip 报告的 Qwen2.5-omni-3B DyCoke (V&A) 版只存在部分任务上的分数落后，甚至在 Music 任务上分数稍微优于压缩 V / A，这可能是因为未压缩的音频 token 提供了更多的音频信息，在其他任务上有所不如的可能是因为部分任务的视频信息更加重要，音频分走了一部分注意力。

### 实验设计

在 baseline 基础上直接通过计算 V / A 双向注意力后，按照时间块分组进行 V/A token 压缩...

在 baseline 基础上，在 V/A 过 MLP 投影且分组交错后加双向注意力得到 N_a + N_v 个 融合token，参照 EchoingPixels ？


### TODO

在 WorldSense 上评估 baseline：

由于 75 上面卡坏了，暂时跑不了实验了, 查了下说是过热或者缺电自我保护断开服务了，得等管服务器的人重启服务器了

```shell
Unable to determine the device handle for GPU0000:B2:00.0: Unknown Error
```












